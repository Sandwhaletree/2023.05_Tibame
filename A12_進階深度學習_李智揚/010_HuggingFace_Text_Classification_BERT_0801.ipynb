{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sandwhaletree/2023.05_Tibame/blob/main/A12_%E9%80%B2%E9%9A%8E%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92_%E6%9D%8E%E6%99%BA%E6%8F%9A/010_HuggingFace_Text_Classification_BERT_0801.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSLdmRPCQKeP"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.28.0\n",
        "!pip install datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ],
      "metadata": {
        "id": "mEyOagctAv3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset\n",
        "\n",
        "[huggingface datasets](https://huggingface.co/docs/datasets/index)"
      ],
      "metadata": {
        "id": "pFmNTP8cQOhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "# load dataset\n",
        "imdb = load_dataset(\"imdb\")"
      ],
      "metadata": {
        "id": "WEyMqrwDQTNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb"
      ],
      "metadata": {
        "id": "TB6FY4w5f0oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print a data with text and label\n",
        "imdb[\"test\"][0]"
      ],
      "metadata": {
        "id": "PbKfQql4QbIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get tokenizer from pre-trained model\n",
        "\n",
        "model list: https://huggingface.co/models"
      ],
      "metadata": {
        "id": "5oXlmj1H7uya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"distilbert-base-uncased\" # \"bert-base-uncased\" ..."
      ],
      "metadata": {
        "id": "gsjkhP1ljbBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# build tokenizer by model name\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "TEG-fAjyQdes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab: word to id mapping\n",
        "tokenizer.get_vocab()"
      ],
      "metadata": {
        "id": "yKGHHXGVkpp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize all data\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"],\n",
        "                     truncation=True,\n",
        "                     max_length=50)\n",
        "\n",
        "tokenized_imdb = imdb.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "EmVIVAXxQeo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_imdb"
      ],
      "metadata": {
        "id": "y-NcDi6Qh9B7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "text: original text\n",
        "\n",
        "**inpupt_ids**: word to index\n",
        "\n",
        "**label**: positive (1) or negative (0)\n",
        "\n",
        "**attention_mask**: token is used is attention layer"
      ],
      "metadata": {
        "id": "2SYb1P_o87Or"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_imdb['train'][0]"
      ],
      "metadata": {
        "id": "Fp88JkeX8ttU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# id to text map\n",
        "id2text = {v: k for k, v in tokenizer.get_vocab().items()}\n",
        "\n",
        "len(id2text)"
      ],
      "metadata": {
        "id": "7mMr9KofVde4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Special token id\n",
        "\n",
        "**\\[PAD\\]**: 0, padding sequence\n",
        "\n",
        "**\\[UNK\\]**: 100, not in vocab\n",
        "\n",
        "**\\[CLS\\]**: 101, whole sequence\n",
        "\n",
        "**\\[SEP\\]**: 102, between 2 sequence\n",
        "\n",
        "**\\[MASK\\]**: 103, predicted masking token in pretraining"
      ],
      "metadata": {
        "id": "hvBieew_9nyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(120):\n",
        "    print(i, id2text[i])"
      ],
      "metadata": {
        "id": "2I-Nww8WV_dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "data = tokenized_imdb[\"train\"][0]\n",
        "\n",
        "for key in ['text', 'label', 'input_ids', 'attention_mask']:\n",
        "    print(f'{key}: ', data[key])"
      ],
      "metadata": {
        "id": "OQLX7gYviB8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dynamic padding\n",
        "'''\n",
        "Itâ€™s more efficient to dynamically pad the sentences to the longest length in a\n",
        "batch during collation, instead of padding the whole dataset to the maximum length.\n",
        "'''\n",
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "VMh4SoNPQf7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Metrics"
      ],
      "metadata": {
        "id": "CCbzidxpzYln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ],
      "metadata": {
        "id": "Cwleb3JKQjgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions,\n",
        "                            references=labels)"
      ],
      "metadata": {
        "id": "MvBuuUdkQlP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# id & label mapping\n",
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
      ],
      "metadata": {
        "id": "h6VrMntMQmZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME, # model name\n",
        "    num_labels=2, # number of classes\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")"
      ],
      "metadata": {
        "id": "uhKyB2_RQnlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 64\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"my_awesome_model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=BS,\n",
        "    per_device_eval_batch_size=BS,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False, # upload to huggingface hub\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_imdb[\"train\"],\n",
        "    eval_dataset=tokenized_imdb[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "RCDHOhiAQpAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inference\n",
        "\n",
        "pipeline: https://huggingface.co/docs/transformers/v4.28.1/en/quicktour#pipeline"
      ],
      "metadata": {
        "id": "VjLhiyu7yyU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.\""
      ],
      "metadata": {
        "id": "CyORaXiKQqsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", # task\n",
        "                    #   model=\"stevhliu/my_awesome_model\", # from huggingface hub\n",
        "                      model=\"./my_awesome_model/checkpoint-782\", # local\n",
        "                      )\n",
        "\n",
        "classifier(text)"
      ],
      "metadata": {
        "id": "BC8L2TBaQu6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Resources\n",
        "\n",
        "1. Custom dataset: https://huggingface.co/transformers/v3.2.0/custom_datasets.html#seq-imdb\n",
        "2. Notebooks: https://huggingface.co/docs/transformers/notebooks\n",
        "3. Pipeline: https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/pipelines\n",
        "4. More NLP tasks:\n",
        "    *   [Token classification](https://huggingface.co/docs/transformers/tasks/token_classification)\n",
        "    *   [Summarization](https://huggingface.co/docs/transformers/tasks/summarization)\n",
        "    * [Multiple choice](https://huggingface.co/docs/transformers/tasks/multiple_choice)\n",
        "    * [Translation](https://huggingface.co/docs/transformers/tasks/translation)\n",
        "    * [More tasks in NLP, CV, Audio](https://huggingface.co/docs/transformers/index)"
      ],
      "metadata": {
        "id": "OToAvAkDz-ZI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bi-Feo0yQxWs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}