{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sandwhaletree/2023.05_Tibame/blob/main/A12_%E9%80%B2%E9%9A%8E%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92_%E6%9D%8E%E6%99%BA%E6%8F%9A/016_face_recognition_0810.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install facenet-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Mp6PCCH8Z9H",
        "outputId": "fd95b551-1b05-47f3-dde7-02cb0fe49395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (2.31.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (0.15.2+cu118)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (2023.7.22)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision->facenet-pytorch) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision->facenet-pytorch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision->facenet-pytorch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision->facenet-pytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision->facenet-pytorch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/timesler/facenet-pytorch.git"
      ],
      "metadata": {
        "id": "9evdBvy18-4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt3z88X27-Og"
      },
      "source": [
        "# Face detection and recognition inference pipeline\n",
        "\n",
        "The following example illustrates how to use the `facenet_pytorch` python package to perform face detection and recogition on an image dataset using an Inception Resnet V1 pretrained on the VGGFace2 dataset.\n",
        "\n",
        "The following Pytorch methods are included:\n",
        "* Datasets\n",
        "* Dataloaders\n",
        "* GPU/CPU processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Fj8Y32r7-Oi"
      },
      "outputs": [],
      "source": [
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "workers = 0 if os.name == 'nt' else 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAAJYl9w7-Oj"
      },
      "source": [
        "#### Determine if an nvidia GPU is available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raoR9u977-Oj",
        "outputId": "8bd0de74-0d71-462b-abed-63e8e2008d22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Running on device: {}'.format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doOnSJoN7-Ok"
      },
      "source": [
        "#### Define MTCNN module\n",
        "\n",
        "Default params shown for illustration, but not needed. Note that, since MTCNN is a collection of neural nets and other code, the device must be passed in the following way to enable copying of objects when needed internally.\n",
        "\n",
        "See `help(MTCNN)` for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKq_yJlo7-Ok"
      },
      "outputs": [],
      "source": [
        "mtcnn = MTCNN(\n",
        "    image_size=160, margin=0, min_face_size=20,\n",
        "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C3eWu9x7-Ok"
      },
      "source": [
        "#### Define Inception Resnet V1 module\n",
        "\n",
        "Set classify=True for pretrained classifier. For this example, we will use the model to output embeddings/CNN features. Note that for inference, it is important to set the model to `eval` mode.\n",
        "\n",
        "See `help(InceptionResnetV1)` for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb4FHNmL7-Ok"
      },
      "outputs": [],
      "source": [
        "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1FkB-W17-Ok"
      },
      "source": [
        "#### Define a dataset and data loader\n",
        "\n",
        "We add the `idx_to_class` attribute to the dataset to enable easy recoding of label indices to identity names later one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX7PxeDY7-Ok"
      },
      "outputs": [],
      "source": [
        "def collate_fn(x):\n",
        "    return x[0]\n",
        "\n",
        "dataset = datasets.ImageFolder('/content/facenet-pytorch/data/test_images')\n",
        "dataset.idx_to_class = {i:c for c, i in dataset.class_to_idx.items()}\n",
        "loader = DataLoader(dataset, collate_fn=collate_fn, num_workers=workers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL4zxq1Q7-Ok"
      },
      "source": [
        "#### Perfom MTCNN facial detection\n",
        "\n",
        "Iterate through the DataLoader object and detect faces and associated detection probabilities for each. The `MTCNN` forward method returns images cropped to the detected face, if a face was detected. By default only a single detected face is returned - to have `MTCNN` return all detected faces, set `keep_all=True` when creating the MTCNN object above.\n",
        "\n",
        "To obtain bounding boxes rather than cropped face images, you can instead call the lower-level `mtcnn.detect()` function. See `help(mtcnn.detect)` for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHW-F3DM7-Ol"
      },
      "outputs": [],
      "source": [
        "aligned = []\n",
        "names = []\n",
        "for x, y in loader:\n",
        "    x_aligned, prob = mtcnn(x, return_prob=True)\n",
        "    if x_aligned is not None:\n",
        "        print('Face detected with probability: {:8f}'.format(prob))\n",
        "        aligned.append(x_aligned)\n",
        "        names.append(dataset.idx_to_class[y])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skLwsVG37-Ol"
      },
      "source": [
        "#### Calculate image embeddings\n",
        "\n",
        "MTCNN will return images of faces all the same size, enabling easy batch processing with the Resnet recognition module. Here, since we only have a few images, we build a single batch and perform inference on it.\n",
        "\n",
        "For real datasets, code should be modified to control batch sizes being passed to the Resnet, particularly if being processed on a GPU. For repeated testing, it is best to separate face detection (using MTCNN) from embedding or classification (using InceptionResnetV1), as calculation of cropped faces or bounding boxes can then be performed a single time and detected faces saved for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkEUltUD7-Ol"
      },
      "outputs": [],
      "source": [
        "aligned = torch.stack(aligned).to(device)\n",
        "embeddings = resnet(aligned).detach().cpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGEFg1bS7-Ol"
      },
      "source": [
        "#### Print distance matrix for classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJ4O0tDZ7-Ol"
      },
      "outputs": [],
      "source": [
        "dists = [[(e1 - e2).norm().item() for e2 in embeddings] for e1 in embeddings]\n",
        "print(pd.DataFrame(dists, columns=names, index=names))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xdcNcFv-9Kaz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}